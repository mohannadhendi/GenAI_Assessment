# ğŸ“š Library Desk Agent

An **AI-powered Library Management Assistant** built with **FastAPI**, **LangChain**, and **Streamlit**.  
It helps manage books, customers, and orders through natural language queries.

## ğŸš€ Features

- ğŸ¤– GPT-powered intelligent assistant (LangChain Agent)
- âš¡ FastAPI backend with tool orchestration
- ğŸ–¥ï¸ Streamlit interactive frontend
- ğŸ—„ï¸ PostgreSQL database with SQLAlchemy ORM
- ğŸ”„ Auto tool chaining (find_books â†’ restock_book â†’ create_order â†’ ...)
- ğŸ’¬ Persistent chat sessions with database logging

## ğŸ§© Project Structure

```
GenAI_Assessment/
â”œâ”€â”€ app/
â”‚   â””â”€â”€ chat_ui.py             # Streamlit frontend
â”œâ”€â”€ server/
â”‚   â”œâ”€â”€ main.py                # FastAPI + Streamlit launcher
â”‚   â”œâ”€â”€ db.py                  # Database connection
â”‚   â”œâ”€â”€ models/                # SQLAlchemy models
â”‚   â”œâ”€â”€ agent/
â”‚   â”‚   â”œâ”€â”€ chains/            # LangChain agent logic
â”‚   â”‚   â””â”€â”€ tools/             # Custom AI tools
â”‚   â”œâ”€â”€ routes/                # FastAPI endpoints
â”‚   â””â”€â”€ config.py              # Environment settings
â”œâ”€â”€ db/
â”‚   â””â”€â”€ seed.py                # Seed script to populate sample data
â””â”€â”€ README.md
```

## âš™ï¸ Installation & Setup

### 1. Clone the Repository

```bash
git clone <your-repo-url>
cd GenAI_Assessment
```

### 2. Create and Activate Virtual Environment

```bash
conda create -n desk-agent python=3.11 -y
conda activate desk-agent
```

### 3. Install Dependencies

```bash
pip install -r requirements.txt
```

### 4. Configure Environment

Create a `.env` file in the project root:

```env
APP_NAME="" 
APP_VERSION=""
OPENAI_API_KEY=""
POSTGRES_DB_URL=""
POSTGRES_DB_NAME=""
POSTGRES_DB_USER=""
POSTGRES_DB_PASSWORD=""
API_URL=""
```

**Environment Variables:**
- `APP_NAME`: Application name displayed in the UI
- `APP_VERSION`: Current version of the application
- `OPENAI_API_KEY`: Your OpenAI API key for GPT integration
- `POSTGRES_DB_URL`: Full PostgreSQL connection string
- `POSTGRES_DB_NAME`: Database name (e.g., `library_db`)
- `POSTGRES_DB_USER`: Database username
- `POSTGRES_DB_PASSWORD`: Database password
- `API_URL`: Backend API endpoint for chat requests

## ğŸŒ± Database Setup

### Automatic Table Creation
When you run the application for the first time, all database tables are created automatically through SQLAlchemy ORM migrations.

### Data Seeding
To populate initial books, customers, and sample data:

```bash
cd ~/path/to/your/project
python -m db.seed
```


### Manual Schema Setup (Troubleshooting)
If you encounter any database issues, you can manually create the schema using the provided SQL file:

```bash
psql -U your_username -d library_db -f seed.sql
```

This will create all necessary tables and constraints for the application.

## â–¶ï¸ Run the Project

You can run FastAPI and Streamlit together from one terminal:

```bash
python -m server.main
```

Once launched:
- FastAPI runs on â†’ `http://127.0.0.1:5000`
- Streamlit UI runs on â†’ `http://127.0.0.1:8501`

## ğŸ§  Example Queries (Test Cases)

You can test directly in the Streamlit chat or via API calls.

### ğŸ” Find Book
```json
{ "query": "Find books by Robert C. Martin" }
```

### ğŸ“¦ Restock Book
```json
{ "query": "Restock Clean Code book by 45" }
```

### ğŸ›’ Create Order
```json
{ "query": "Create an order for customer 2 for 2 copies of Clean Code" }
```

### ğŸ’° Update Price
```json
{ "query": "Update the price of Clean Code to 50 dollars" }
```

### ğŸ“‘ Order Status
```json
{ "query": "What is the status of order 2?" }
```

### ğŸ“‰ Inventory Summary
```json
{ "query": "Show me all books that are running low on stock" }
```

## ğŸ§ª API Reference

| Endpoint | Method | Description |
|----------|--------|-------------|
| `/` | GET | Health Check |
| `/chat` | POST | Send a query to the AI agent |
| `/sessions` | GET | List all chat sessions |
| `/messages/{session_id}` | GET | Retrieve chat history for a specific session |


## ğŸ‘¨â€ğŸ’» Developed By:

**Mohannad Hendi**  
Senior AI Engineer â€¢ Automation Specialist â€¢ Data Scientist
